# 1. Convert datestamp column to a datetime object and Set the datestamp columns as the index of your DataFrame.
emp['datestamp']= pd.to_datetime(emp['datestamp'])

# 3.Find any missing review are present or not,if present remove those data.

amz.isnull().sum()
amz.dropna(subset=['review'],inplace=True)
amz.dropna(subset=['name'],inplace=True)
amz.isnull().sum()

CLEANING TEXTUAL DATA 

amz['review'] = amz['review'].apply(lambda x:contr(x))
amz['review'] = amz['review'].str.replace("[^a-zA-Z#]", " ")
amz['review'] = amz['review'].str.casefold()
amz

# 5.Add the Polarity, length of the review, the word count and average word length of each review.

from textblob import TextBlob
amz['polarity'] = amz['review'].map(lambda text: TextBlob(text).sentiment.polarity)
amz['review_len'] = amz['review'].astype(str).apply(len)
amz['word_count'] = amz['review'].apply(lambda x: len(str(x).split()))
amz


polarity and rating?

# 7.Visualize polarity considering the rating.

amz.groupby(by='rating').polarity.agg([np.mean]).plot()
plt.xlabel('rating',fontsize=12)
plt.ylabel('polarity',fontsize=12)
plt.title('Polarity considering Rating')
plt.legend(fontsize=15,loc='upper left')
plt.show()




N GRAMS:

from sklearn.feature_extraction.text import CountVectorizer
def top_words(x, n=25):
    vec = CountVectorizer(stop_words='english').fit(x)
    bag_of_words = vec.transform(x)
    sum_words = bag_of_words.sum(axis=0) 
    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]
    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)
    return words_freq[:n]
    
    
    words = top_words(amz['review'], 25)
words

dfu = pd.DataFrame(words, columns = ['UnigramText' , 'Count'])
dfu


plot=dfu.plot.bar(x='UnigramText',y='Count',figsize=(17,7),width =0.75)
plt.legend(fontsize=15,loc='upper right')
plot.bar_label(plot.containers[0])
plt.xlabel('unigrams',fontsize=15)
plt.ylabel('count',fontsize=15)
plt.xticks(fontsize=12)
plt.title('Unigrams Count',fontsize=15)
plt.show()


def get_top_n_bigram(x, n=25):
    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(x)
    bag_of_words = vec.transform(x)
    sum_words = bag_of_words.sum(axis=0) 
    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]
    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)
    return words_freq[:n]
    
    common_words = get_top_n_bigram(amz['review'], 25)
common_words


dfb = pd.DataFrame(common_words, columns = ['BigramText' , 'Count'])
dfb
